{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2c4377-4f1c-4db2-a25a-0cf95cc4a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "second_row = df.iloc[1]\n",
    "print(second_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b63bd38-8ca5-421e-ae42-05e5ced35375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In pandas, the loc and iloc functions are used to access data in a DataFrame, but they have some differences in terms of indexing methods.\\n\\nloc: This function is primarily label-based, meaning it is used to access data based on the labels of rows or columns. It accepts label-based indexing and returns data based on the row and column labels.\\n\\niloc: This function is primarily integer-based, meaning it is used to access data based on the integer positions of rows or columns. It accepts integer-based indexing and returns data based on the row and column positions.\\n\\nHere are the key differences between loc and iloc:\\n\\nloc uses label-based indexing, while iloc uses integer-based indexing.\\nloc includes the end value in slicing, while iloc excludes the end value. For example, df.loc[1:3] will include rows with labels 1, 2, and 3, while df.iloc[1:3] will include rows with positions 1 and 2 (excluding 3).\\nloc can accept labels for both rows and columns, while iloc only accepts integer positions for rows and columns.\\nloc can accept boolean masks or callable functions as indexing criteria, while iloc only accepts integer positions or slices.\\nIn summary, loc is used for label-based indexing with inclusion of the end value, while iloc is used for integer-based indexing with exclusion of the end value.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.\n",
    "\n",
    "'''In pandas, the loc and iloc functions are used to access data in a DataFrame, but they have some differences in terms of indexing methods.\n",
    "\n",
    "loc: This function is primarily label-based, meaning it is used to access data based on the labels of rows or columns. It accepts label-based indexing and returns data based on the row and column labels.\n",
    "\n",
    "iloc: This function is primarily integer-based, meaning it is used to access data based on the integer positions of rows or columns. It accepts integer-based indexing and returns data based on the row and column positions.\n",
    "\n",
    "Here are the key differences between loc and iloc:\n",
    "\n",
    "loc uses label-based indexing, while iloc uses integer-based indexing.\n",
    "loc includes the end value in slicing, while iloc excludes the end value. For example, df.loc[1:3] will include rows with labels 1, 2, and 3, while df.iloc[1:3] will include rows with positions 1 and 2 (excluding 3).\n",
    "loc can accept labels for both rows and columns, while iloc only accepts integer positions for rows and columns.\n",
    "loc can accept boolean masks or callable functions as indexing criteria, while iloc only accepts integer positions or slices.\n",
    "In summary, loc is used for label-based indexing with inclusion of the end value, while iloc is used for integer-based indexing with exclusion of the end value.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08119a97-c5d4-4d28-9732-b32a786df57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "print(new_df.loc[2])\n",
    "print(new_df.iloc[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7482980f-6fbc-4537-9770-78608bd65e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.324466\n",
      "column_2    0.317226\n",
      "column_3    0.465776\n",
      "column_4    0.533343\n",
      "column_5    0.487869\n",
      "column_6    0.345726\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#4.(i)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17945b4-b646-4b86-8ade-bd02fa636735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard deviation of 'column_2':\n",
      "0.3388652006500538\n"
     ]
    }
   ],
   "source": [
    "#(ii)# Standard deviation of column 'column_2'\n",
    "column_2_std = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\")\n",
    "print(column_2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49165102-5b50-41e8-83fe-e5779bd1000a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplacement_string\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m column_2_mean \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(column_2_mean)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'replacement_string'\n",
    "df1['column_2'] = pd.to_numeric(df1['column_2'], errors='coerce')",
    "\n",
    "# Calculate the mean of 'column_2'\n",
    "column_2_mean = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2':\")\n",
    "print(column_2_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb571b2-9c08-4c98-88b6-128de590abe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In pandas, the windows functions are used for performing calculations on a rolling or expanding window of data within a DataFrame or Series. These functions allow you to apply various operations, such as aggregation, transformation, or filtering, to a specific window of data defined by its size and position.\\n\\nThe types of windows functions available in pandas are:\\n\\nRolling Windows: These functions operate on a fixed-size sliding window of data and perform calculations within that window as it moves along the data. Some common rolling windows functions include:\\n\\nrolling(): Creates a rolling window object.\\nmean(): Calculates the mean of the window.\\nsum(): Calculates the sum of the window.\\nstd(): Calculates the standard deviation of the window.\\nmin(): Calculates the minimum value in the window.\\nmax(): Calculates the maximum value in the window.\\nquantile(): Calculates the specified quantile in the window.\\napply(): Applies a custom function to the window.\\nExpanding Windows: These functions progressively expand the window size as it moves along the data. They consider all the data points from the start until the current position of the window. Some common expanding windows functions include:\\n\\nexpanding(): Creates an expanding window object.\\nmean(): Calculates the mean of the expanding window.\\nsum(): Calculates the sum of the expanding window.\\nstd(): Calculates the standard deviation of the expanding window.\\nmin(): Calculates the minimum value in the expanding window.\\nmax(): Calculates the maximum value in the expanding window.\\nquantile(): Calculates the specified quantile in the expanding window.\\napply(): Applies a custom function to the expanding window.\\nThese windows functions provide flexibility in performing calculations on rolling or expanding windows of data, allowing you to gain insights into trends, patterns, or summarize data over time.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.\n",
    "\n",
    "'''In pandas, the windows functions are used for performing calculations on a rolling or expanding window of data within a DataFrame or Series. These functions allow you to apply various operations, such as aggregation, transformation, or filtering, to a specific window of data defined by its size and position.\n",
    "\n",
    "The types of windows functions available in pandas are:\n",
    "\n",
    "Rolling Windows: These functions operate on a fixed-size sliding window of data and perform calculations within that window as it moves along the data. Some common rolling windows functions include:\n",
    "\n",
    "rolling(): Creates a rolling window object.\n",
    "mean(): Calculates the mean of the window.\n",
    "sum(): Calculates the sum of the window.\n",
    "std(): Calculates the standard deviation of the window.\n",
    "min(): Calculates the minimum value in the window.\n",
    "max(): Calculates the maximum value in the window.\n",
    "quantile(): Calculates the specified quantile in the window.\n",
    "apply(): Applies a custom function to the window.\n",
    "Expanding Windows: These functions progressively expand the window size as it moves along the data. They consider all the data points from the start until the current position of the window. Some common expanding windows functions include:\n",
    "\n",
    "expanding(): Creates an expanding window object.\n",
    "mean(): Calculates the mean of the expanding window.\n",
    "sum(): Calculates the sum of the expanding window.\n",
    "std(): Calculates the standard deviation of the expanding window.\n",
    "min(): Calculates the minimum value in the expanding window.\n",
    "max(): Calculates the maximum value in the expanding window.\n",
    "quantile(): Calculates the specified quantile in the expanding window.\n",
    "apply(): Applies a custom function to the expanding window.\n",
    "These windows functions provide flexibility in performing calculations on rolling or expanding windows of data, allowing you to gain insights into trends, patterns, or summarize data over time.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65da6774-089d-4768-a347-60d2d887d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month: 5\n",
      "Current year: 2023\n"
     ]
    }
   ],
   "source": [
    "#7.\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now()\n",
    "\n",
    "# Extract the month and year from the current date\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current month:\", current_month)\n",
    "print(\"Current year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccaa8f4-d076-446c-b43b-742dbe31f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2002-11-11\n",
      "Enter the second date (YYYY-MM-DD):  2003-11-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between the dates:\n",
      "Days: 365\n",
      "Hours: 0\n",
      "Minutes: 0\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the dates\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert the input dates to Pandas datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# Calculate the time difference using Pandas Timedelta\n",
    "time_diff = date2 - date1\n",
    "\n",
    "# Extract the days, hours, and minutes from the time difference\n",
    "days = time_diff.days\n",
    "hours = time_diff.seconds // 3600\n",
    "minutes = (time_diff.seconds % 3600) // 60\n",
    "\n",
    "# Display the result\n",
    "print(\"Difference between the dates:\")\n",
    "print(f\"Days: {days}\")\n",
    "print(f\"Hours: {hours}\")\n",
    "print(f\"Minutes: {minutes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933c90b1-338c-4469-b467-97305417915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file:  winequality-red.csv\n",
      "Enter the column name to convert:  chlorides\n",
      "Enter the category order (comma-separated):  Low,Medium,High\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Data:\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar chlorides  \\\n",
      "0               7.4             0.700         0.00             1.9       NaN   \n",
      "1               7.8             0.880         0.00             2.6       NaN   \n",
      "2               7.8             0.760         0.04             2.3       NaN   \n",
      "3              11.2             0.280         0.56             1.9       NaN   \n",
      "4               7.4             0.700         0.00             1.9       NaN   \n",
      "...             ...               ...          ...             ...       ...   \n",
      "1594            6.2             0.600         0.08             2.0       NaN   \n",
      "1595            5.9             0.550         0.10             2.2       NaN   \n",
      "1596            6.3             0.510         0.13             2.3       NaN   \n",
      "1597            5.9             0.645         0.12             2.0       NaN   \n",
      "1598            6.0             0.310         0.47             3.6       NaN   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        5  \n",
      "1         9.8        5  \n",
      "2         9.8        5  \n",
      "3         9.8        6  \n",
      "4         9.4        5  \n",
      "...       ...      ...  \n",
      "1594     10.5        5  \n",
      "1595     11.2        6  \n",
      "1596     11.0        6  \n",
      "1597     10.2        5  \n",
      "1598     11.0        6  \n",
      "\n",
      "[1599 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Prompt the user to enter the column name and category order\n",
    "column_name = input(\"Enter the column name to convert: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "# Convert the specified column to a categorical data type with the specified order\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the data based on the specified column\n",
    "sorted_df = df.sort_values(by=column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280e429a-b9bc-4581-b4e4-b6e36c6cdf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Prompt the user to enter the file path\\nfile_path = input(\"Enter the file path of the CSV file: \")\\n\\n# Read the CSV file\\ndf = pd.read_csv(file_path)\\n\\n# Convert the \\'Date\\' column to a datetime type\\ndf[\\'Date\\'] = pd.to_datetime(df[\\'Date\\'])\\n\\n# Group the data by \\'Date\\' and \\'Category\\' and calculate the sum of \\'Sales\\'\\ngrouped_data = df.groupby([\\'Date\\', \\'Category\\'])[\\'Sales\\'].sum().unstack()\\n\\n# Plot the stacked bar chart\\ngrouped_data.plot(kind=\\'bar\\', stacked=True)\\n\\n# Set the chart title and axis labels\\nplt.title(\\'Sales by Product Category over Time\\')\\nplt.xlabel(\\'Date\\')\\nplt.ylabel(\\'Sales\\')\\n\\n# Show the chart\\nplt.show()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.\n",
    "\n",
    "'''import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Date' column to a datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by 'Date' and 'Category' and calculate the sum of 'Sales'\n",
    "grouped_data = df.groupby(['Date', 'Category'])['Sales'].sum().unstack()\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "grouped_data.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title('Sales by Product Category over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d0814-ac46-496b-a245-4040067680f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode()\n",
    "\n",
    "# Display the results in a table\n",
    "table_data = {'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "              'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]}\n",
    "table = pd.DataFrame(table_data)\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a53ab9-f0b3-4c34-b3e2-06a8da2e1eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
