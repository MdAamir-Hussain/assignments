{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "988d254c-9c32-42be-865b-83237dba20eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To design the pipeline for your machine learning project, you can use scikit-learn, a popular Python library for machine learning. Here's an outline of the pipeline:\\n\\nFeature Selection:\\n\\nUse an automated feature selection method, such as Recursive Feature Elimination (RFE) or feature importance from a tree-based model, to identify the important features in the dataset.\\nNumerical Pipeline:\\n\\nFor numerical columns, you can use the SimpleImputer class from scikit-learn to impute missing values with the mean of the column values.\\nUse the StandardScaler class to scale the numerical columns using standardization.\\nCategorical Pipeline:\\n\\nFor categorical columns, you can use the SimpleImputer class to impute missing values with the most frequent value of the column.\\nApply one-hot encoding to the categorical columns using the OneHotEncoder class.\\nColumnTransformer:\\n\\nUse the ColumnTransformer class to combine the numerical and categorical pipelines.\\nSpecify the transformations for each column, mapping the numerical and categorical pipelines to their respective column types.\\nRandom Forest Classifier:\\n\\nUse the RandomForestClassifier class from scikit-learn as your final model.\\nYou can set the desired hyperparameters for the classifier, such as the number of trees, maximum depth, etc.\\nEvaluation:\\n\\nSplit your dataset into training and testing sets using train_test_split from scikit-learn.\\nFit the pipeline on the training data using the fit method.\\nUse the trained pipeline to predict the target variable on the test data.\\nEvaluate the accuracy of the model using appropriate metrics, such as accuracy_score from scikit-learn.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.\n",
    "\n",
    "'''To design the pipeline for your machine learning project, you can use scikit-learn, a popular Python library for machine learning. Here's an outline of the pipeline:\n",
    "\n",
    "Feature Selection:\n",
    "\n",
    "Use an automated feature selection method, such as Recursive Feature Elimination (RFE) or feature importance from a tree-based model, to identify the important features in the dataset.\n",
    "Numerical Pipeline:\n",
    "\n",
    "For numerical columns, you can use the SimpleImputer class from scikit-learn to impute missing values with the mean of the column values.\n",
    "Use the StandardScaler class to scale the numerical columns using standardization.\n",
    "Categorical Pipeline:\n",
    "\n",
    "For categorical columns, you can use the SimpleImputer class to impute missing values with the most frequent value of the column.\n",
    "Apply one-hot encoding to the categorical columns using the OneHotEncoder class.\n",
    "ColumnTransformer:\n",
    "\n",
    "Use the ColumnTransformer class to combine the numerical and categorical pipelines.\n",
    "Specify the transformations for each column, mapping the numerical and categorical pipelines to their respective column types.\n",
    "Random Forest Classifier:\n",
    "\n",
    "Use the RandomForestClassifier class from scikit-learn as your final model.\n",
    "You can set the desired hyperparameters for the classifier, such as the number of trees, maximum depth, etc.\n",
    "Evaluation:\n",
    "\n",
    "Split your dataset into training and testing sets using train_test_split from scikit-learn.\n",
    "Fit the pipeline on the training data using the fit method.\n",
    "Use the trained pipeline to predict the target variable on the test data.\n",
    "Evaluate the accuracy of the model using appropriate metrics, such as accuracy_score from scikit-learn.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1053f237-a662-4fcb-9eba-a0edb4683bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create individual classifiers\n",
    "rf_classifier = RandomForestClassifier()\n",
    "lr_classifier = LogisticRegression()\n",
    "\n",
    "# Create a voting classifier with the individual classifiers\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', rf_classifier), ('lr', lr_classifier)],\n",
    "    voting='soft'  # Use soft voting for probabilities-based combination\n",
    ")\n",
    "\n",
    "# Create a pipeline with the voting classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Feature scaling\n",
    "    ('voting', voting_classifier)  # Voting classifier\n",
    "])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b18e8-907b-4b9d-9850-f71e7495b9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
