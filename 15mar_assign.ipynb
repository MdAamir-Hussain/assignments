{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35710cd9-280b-44bb-9291-f78fdc4444c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Artificial Intelligence (AI) refers to the ability of machines to perform tasks that typically require human intelligence, such as recognizing speech, making decisions, and learning. AI can be broadly divided into two categories: narrow or weak AI and general or strong AI. Narrow AI is designed to perform specific tasks, while general AI is capable of performing any intellectual task that a human can.\\nExample: A voice-activated virtual assistant such as Amazon's Alexa or Apple's Siri is an example of narrow AI. These assistants are designed to perform specific tasks such as setting alarms, playing music, or answering questions.\\n\\nMachine Learning (ML) is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. In other words, machine learning models can automatically learn and improve from experience.\\nExample: An example of machine learning is a spam filter for email. The filter can learn from the patterns in the emails that are marked as spam by the user, and automatically identify and block similar messages in the future.\\n\\nDeep Learning (DL) is a subset of machine learning that uses neural networks, which are modeled after the structure of the human brain, to learn from large amounts of data. Deep learning algorithms can automatically discover intricate patterns in data and make highly accurate predictions or decisions.\\nExample: An example of deep learning is image recognition. Deep learning algorithms can learn to recognize patterns in images, such as the shape of objects or the presence of certain features, and classify the images accordingly. This technology is used in various applications such as self-driving cars, medical imaging, and facial recognition.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.\n",
    "'''Artificial Intelligence (AI) refers to the ability of machines to perform tasks that typically require human intelligence, such as recognizing speech, making decisions, and learning. AI can be broadly divided into two categories: narrow or weak AI and general or strong AI. Narrow AI is designed to perform specific tasks, while general AI is capable of performing any intellectual task that a human can.\n",
    "Example: A voice-activated virtual assistant such as Amazon's Alexa or Apple's Siri is an example of narrow AI. These assistants are designed to perform specific tasks such as setting alarms, playing music, or answering questions.\n",
    "\n",
    "Machine Learning (ML) is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. In other words, machine learning models can automatically learn and improve from experience.\n",
    "Example: An example of machine learning is a spam filter for email. The filter can learn from the patterns in the emails that are marked as spam by the user, and automatically identify and block similar messages in the future.\n",
    "\n",
    "Deep Learning (DL) is a subset of machine learning that uses neural networks, which are modeled after the structure of the human brain, to learn from large amounts of data. Deep learning algorithms can automatically discover intricate patterns in data and make highly accurate predictions or decisions.\n",
    "Example: An example of deep learning is image recognition. Deep learning algorithms can learn to recognize patterns in images, such as the shape of objects or the presence of certain features, and classify the images accordingly. This technology is used in various applications such as self-driving cars, medical imaging, and facial recognition.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6eeb31-dbd6-4600-b50a-2d49003f9d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supervised learning is a type of machine learning where the algorithm learns to make predictions or decisions by training on labeled data. In other words, the input data is labeled with the correct output, and the algorithm learns to map the input to the output.\\n\\nIn supervised learning, the algorithm is given a set of labeled data as input, and it tries to learn a function that can map new input data to the correct output. The algorithm iteratively adjusts its parameters until it achieves the desired level of accuracy.\\n\\nExamples of supervised learning include:\\n\\nImage classification - an algorithm learns to classify images into different categories, such as cats and dogs, based on labeled training data.\\n\\nSpam filtering - an algorithm learns to classify emails as spam or not spam based on labeled training data.\\n\\nSentiment analysis - an algorithm learns to classify text as positive or negative sentiment based on labeled training data.\\n\\nPredictive maintenance - an algorithm learns to predict when a machine is likely to fail based on labeled data on past machine failures.\\n\\nFraud detection - an algorithm learns to detect fraudulent transactions based on labeled data on past fraudulent transactions.\\n\\nCredit risk assessment - an algorithm learns to predict the creditworthiness of a borrower based on labeled data on past loan performance.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.\n",
    "'''Supervised learning is a type of machine learning where the algorithm learns to make predictions or decisions by training on labeled data. In other words, the input data is labeled with the correct output, and the algorithm learns to map the input to the output.\n",
    "\n",
    "In supervised learning, the algorithm is given a set of labeled data as input, and it tries to learn a function that can map new input data to the correct output. The algorithm iteratively adjusts its parameters until it achieves the desired level of accuracy.\n",
    "\n",
    "Examples of supervised learning include:\n",
    "\n",
    "Image classification - an algorithm learns to classify images into different categories, such as cats and dogs, based on labeled training data.\n",
    "\n",
    "Spam filtering - an algorithm learns to classify emails as spam or not spam based on labeled training data.\n",
    "\n",
    "Sentiment analysis - an algorithm learns to classify text as positive or negative sentiment based on labeled training data.\n",
    "\n",
    "Predictive maintenance - an algorithm learns to predict when a machine is likely to fail based on labeled data on past machine failures.\n",
    "\n",
    "Fraud detection - an algorithm learns to detect fraudulent transactions based on labeled data on past fraudulent transactions.\n",
    "\n",
    "Credit risk assessment - an algorithm learns to predict the creditworthiness of a borrower based on labeled data on past loan performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb58757-f0f7-4987-92e9-2736463ad64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unsupervised learning is a type of machine learning where the algorithm learns to find patterns or structure in the input data without explicit labeling of the output. In other words, the algorithm is given a set of input data without any explicit output, and it learns to find the underlying structure or relationships in the data.\\n\\nIn unsupervised learning, the algorithm typically clusters or groups the input data based on similarities or differences between the data points. The algorithm does not have a specific output to predict, and it is up to the user to interpret the results and find meaning in the discovered patterns.\\n\\nExamples of unsupervised learning include:\\n\\nClustering - an algorithm groups data points into clusters based on their similarity or proximity to each other. For example, clustering can be used to group customers based on their purchasing behavior.\\n\\nAnomaly detection - an algorithm identifies data points that are significantly different from the rest of the data. For example, anomaly detection can be used to detect fraudulent transactions in a credit card dataset.\\n\\nDimensionality reduction - an algorithm reduces the dimensionality of the input data while preserving the important information. For example, principal component analysis (PCA) can be used to reduce the number of variables in a dataset.\\n\\nAssociation rule learning - an algorithm finds the relationships between variables in the input data. For example, association rule learning can be used to identify the items that are frequently bought together in a supermarket.\\n\\nGenerative models - an algorithm learns to generate new data that is similar to the input data. For example, a generative model can be used to generate new images that resemble a given set of images.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.\n",
    "'''Unsupervised learning is a type of machine learning where the algorithm learns to find patterns or structure in the input data without explicit labeling of the output. In other words, the algorithm is given a set of input data without any explicit output, and it learns to find the underlying structure or relationships in the data.\n",
    "\n",
    "In unsupervised learning, the algorithm typically clusters or groups the input data based on similarities or differences between the data points. The algorithm does not have a specific output to predict, and it is up to the user to interpret the results and find meaning in the discovered patterns.\n",
    "\n",
    "Examples of unsupervised learning include:\n",
    "\n",
    "Clustering - an algorithm groups data points into clusters based on their similarity or proximity to each other. For example, clustering can be used to group customers based on their purchasing behavior.\n",
    "\n",
    "Anomaly detection - an algorithm identifies data points that are significantly different from the rest of the data. For example, anomaly detection can be used to detect fraudulent transactions in a credit card dataset.\n",
    "\n",
    "Dimensionality reduction - an algorithm reduces the dimensionality of the input data while preserving the important information. For example, principal component analysis (PCA) can be used to reduce the number of variables in a dataset.\n",
    "\n",
    "Association rule learning - an algorithm finds the relationships between variables in the input data. For example, association rule learning can be used to identify the items that are frequently bought together in a supermarket.\n",
    "\n",
    "Generative models - an algorithm learns to generate new data that is similar to the input data. For example, a generative model can be used to generate new images that resemble a given set of images.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a452fd9a-f9f0-4c0d-814f-77a306fb68cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are all related concepts in the field of computer science, but they have different meanings and applications.\\n\\nAI refers to the ability of machines to perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and natural language processing.\\n\\nML is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. In other words, machine learning models can automatically learn and improve from experience.\\n\\nDL is a subset of ML that uses neural networks, which are modeled after the structure of the human brain, to learn from large amounts of data. Deep learning algorithms can automatically discover intricate patterns in data and make highly accurate predictions or decisions.\\n\\nDS is a multidisciplinary field that involves the use of statistical and computational methods to extract insights and knowledge from data. Data science encompasses various activities, such as data cleaning, data analysis, data visualization, and machine learning.\\n\\nTo summarize the differences between AI, ML, DL, and DS:\\n\\nAI is the broadest term that refers to the ability of machines to perform tasks that typically require human intelligence.\\nML is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed.\\nDL is a subset of ML that uses neural networks to learn from large amounts of data and make highly accurate predictions or decisions.\\nDS is a multidisciplinary field that uses statistical and computational methods to extract insights and knowledge from data, and it includes activities such as data cleaning, data analysis, data visualization, and machine learning.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.\n",
    "'''AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are all related concepts in the field of computer science, but they have different meanings and applications.\n",
    "\n",
    "AI refers to the ability of machines to perform tasks that typically require human intelligence, such as learning, problem-solving, decision-making, and natural language processing.\n",
    "\n",
    "ML is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. In other words, machine learning models can automatically learn and improve from experience.\n",
    "\n",
    "DL is a subset of ML that uses neural networks, which are modeled after the structure of the human brain, to learn from large amounts of data. Deep learning algorithms can automatically discover intricate patterns in data and make highly accurate predictions or decisions.\n",
    "\n",
    "DS is a multidisciplinary field that involves the use of statistical and computational methods to extract insights and knowledge from data. Data science encompasses various activities, such as data cleaning, data analysis, data visualization, and machine learning.\n",
    "\n",
    "To summarize the differences between AI, ML, DL, and DS:\n",
    "\n",
    "AI is the broadest term that refers to the ability of machines to perform tasks that typically require human intelligence.\n",
    "ML is a subset of AI that involves the use of algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed.\n",
    "DL is a subset of ML that uses neural networks to learn from large amounts of data and make highly accurate predictions or decisions.\n",
    "DS is a multidisciplinary field that uses statistical and computational methods to extract insights and knowledge from data, and it includes activities such as data cleaning, data analysis, data visualization, and machine learning.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87177b0b-089c-4fdc-a6df-e245609ac425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supervised, unsupervised, and semi-supervised learning are three different types of machine learning that differ in their approach to learning from data.\\n\\nSupervised learning: In supervised learning, the algorithm learns from labeled data, where the input data is labeled with the correct output. The algorithm learns to map the input to the output and makes predictions on new, unseen data. Supervised learning is used for prediction and classification tasks, where the goal is to learn a function that can accurately predict the output for new inputs.\\n\\nUnsupervised learning: In unsupervised learning, the algorithm learns from unlabeled data, where the input data is not labeled with any output. The algorithm learns to find patterns or structure in the data without any explicit output to predict. Unsupervised learning is used for tasks such as clustering, anomaly detection, and dimensionality reduction, where the goal is to discover the underlying structure or relationships in the data.\\n\\nSemi-supervised learning: In semi-supervised learning, the algorithm learns from a combination of labeled and unlabeled data. The algorithm uses the labeled data to learn a model and then uses the unlabeled data to improve the model further. Semi-supervised learning is used when labeled data is scarce or expensive to obtain, and it can lead to better performance than using either supervised or unsupervised learning alone.\\n\\nThe main differences between these types of learning are:\\n\\nSupervised learning requires labeled data, whereas unsupervised learning does not require any labels.\\nSupervised learning is used for prediction and classification tasks, whereas unsupervised learning is used for tasks such as clustering, anomaly detection, and dimensionality reduction.\\nSemi-supervised learning combines labeled and unlabeled data to improve performance and is used when labeled data is scarce or expensive to obtain.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.\n",
    "'''Supervised, unsupervised, and semi-supervised learning are three different types of machine learning that differ in their approach to learning from data.\n",
    "\n",
    "Supervised learning: In supervised learning, the algorithm learns from labeled data, where the input data is labeled with the correct output. The algorithm learns to map the input to the output and makes predictions on new, unseen data. Supervised learning is used for prediction and classification tasks, where the goal is to learn a function that can accurately predict the output for new inputs.\n",
    "\n",
    "Unsupervised learning: In unsupervised learning, the algorithm learns from unlabeled data, where the input data is not labeled with any output. The algorithm learns to find patterns or structure in the data without any explicit output to predict. Unsupervised learning is used for tasks such as clustering, anomaly detection, and dimensionality reduction, where the goal is to discover the underlying structure or relationships in the data.\n",
    "\n",
    "Semi-supervised learning: In semi-supervised learning, the algorithm learns from a combination of labeled and unlabeled data. The algorithm uses the labeled data to learn a model and then uses the unlabeled data to improve the model further. Semi-supervised learning is used when labeled data is scarce or expensive to obtain, and it can lead to better performance than using either supervised or unsupervised learning alone.\n",
    "\n",
    "The main differences between these types of learning are:\n",
    "\n",
    "Supervised learning requires labeled data, whereas unsupervised learning does not require any labels.\n",
    "Supervised learning is used for prediction and classification tasks, whereas unsupervised learning is used for tasks such as clustering, anomaly detection, and dimensionality reduction.\n",
    "Semi-supervised learning combines labeled and unlabeled data to improve performance and is used when labeled data is scarce or expensive to obtain.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4dfa563-4f63-4f80-8923-c74231846662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In machine learning, the train, test, and validation split refers to the process of dividing a dataset into separate subsets for training, testing, and validating machine learning models.\\n\\nTraining set: The training set is used to train the machine learning model, and it contains the input data and their corresponding output labels.\\n\\nTest set: The test set is used to evaluate the performance of the trained model on unseen data, and it contains input data and their corresponding output labels that were not used during the training phase.\\n\\nValidation set: The validation set is used to tune the hyperparameters of the model and prevent overfitting. It contains input data and their corresponding output labels that were not used during the training or testing phase.\\n\\nThe importance of each split is as follows:\\n\\nTraining set: The training set is used to teach the machine learning model how to make predictions based on input data. It is important that the training set is diverse and representative of the problem space so that the model can generalize well to new, unseen data.\\n\\nTest set: The test set is used to evaluate the performance of the trained model on unseen data. It is important that the test set is representative of the problem space and that it contains data that the model has not seen before. This helps to ensure that the model can generalize well to new, unseen data and is not overfitting to the training set.\\n\\nValidation set: The validation set is used to tune the hyperparameters of the model and prevent overfitting. Hyperparameters are the settings of the model that are not learned from the data, such as the learning rate or the number of hidden layers. By using a separate validation set, we can evaluate the performance of the model with different hyperparameters and select the best combination of hyperparameters that results in the best performance on the validation set.\\n\\nIn summary, the train, test, and validation split is important in machine learning because it allows us to train, test, and tune machine learning models in a way that helps to ensure that the models generalize well to new, unseen data and are not overfitting to the training set.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.\n",
    "'''In machine learning, the train, test, and validation split refers to the process of dividing a dataset into separate subsets for training, testing, and validating machine learning models.\n",
    "\n",
    "Training set: The training set is used to train the machine learning model, and it contains the input data and their corresponding output labels.\n",
    "\n",
    "Test set: The test set is used to evaluate the performance of the trained model on unseen data, and it contains input data and their corresponding output labels that were not used during the training phase.\n",
    "\n",
    "Validation set: The validation set is used to tune the hyperparameters of the model and prevent overfitting. It contains input data and their corresponding output labels that were not used during the training or testing phase.\n",
    "\n",
    "The importance of each split is as follows:\n",
    "\n",
    "Training set: The training set is used to teach the machine learning model how to make predictions based on input data. It is important that the training set is diverse and representative of the problem space so that the model can generalize well to new, unseen data.\n",
    "\n",
    "Test set: The test set is used to evaluate the performance of the trained model on unseen data. It is important that the test set is representative of the problem space and that it contains data that the model has not seen before. This helps to ensure that the model can generalize well to new, unseen data and is not overfitting to the training set.\n",
    "\n",
    "Validation set: The validation set is used to tune the hyperparameters of the model and prevent overfitting. Hyperparameters are the settings of the model that are not learned from the data, such as the learning rate or the number of hidden layers. By using a separate validation set, we can evaluate the performance of the model with different hyperparameters and select the best combination of hyperparameters that results in the best performance on the validation set.\n",
    "\n",
    "In summary, the train, test, and validation split is important in machine learning because it allows us to train, test, and tune machine learning models in a way that helps to ensure that the models generalize well to new, unseen data and are not overfitting to the training set.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb6d7f3-b763-43bd-9941-3e4d3de5bfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unsupervised learning can be used in anomaly detection by identifying patterns in the data that are different or unusual from the majority of the data.\\n\\nOne approach to anomaly detection using unsupervised learning is to use clustering algorithms, such as k-means or DBSCAN, to group similar data points together. Data points that do not fit into any cluster or belong to a small cluster can be considered anomalies. Another approach is to use density-based methods, such as Local Outlier Factor (LOF) or Isolation Forest, to identify data points that are located in low-density areas of the data distribution.\\n\\nThe advantage of using unsupervised learning for anomaly detection is that it does not require labeled data, which can be difficult or expensive to obtain for rare or unexpected events. Unsupervised methods can also detect novel or unknown types of anomalies that were not present in the training data.\\n\\nHowever, unsupervised methods can also produce false positives if the normal data has a complex distribution or if the anomalies are similar to the normal data. Therefore, it is important to carefully select the appropriate unsupervised learning algorithm and tune its parameters to achieve a good balance between false positives and false negatives. In addition, it is often useful to combine unsupervised methods with other techniques, such as expert knowledge or rule-based systems, to improve the accuracy of anomaly detection.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.\n",
    "'''Unsupervised learning can be used in anomaly detection by identifying patterns in the data that are different or unusual from the majority of the data.\n",
    "\n",
    "One approach to anomaly detection using unsupervised learning is to use clustering algorithms, such as k-means or DBSCAN, to group similar data points together. Data points that do not fit into any cluster or belong to a small cluster can be considered anomalies. Another approach is to use density-based methods, such as Local Outlier Factor (LOF) or Isolation Forest, to identify data points that are located in low-density areas of the data distribution.\n",
    "\n",
    "The advantage of using unsupervised learning for anomaly detection is that it does not require labeled data, which can be difficult or expensive to obtain for rare or unexpected events. Unsupervised methods can also detect novel or unknown types of anomalies that were not present in the training data.\n",
    "\n",
    "However, unsupervised methods can also produce false positives if the normal data has a complex distribution or if the anomalies are similar to the normal data. Therefore, it is important to carefully select the appropriate unsupervised learning algorithm and tune its parameters to achieve a good balance between false positives and false negatives. In addition, it is often useful to combine unsupervised methods with other techniques, such as expert knowledge or rule-based systems, to improve the accuracy of anomaly detection.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6150475-e7e1-4052-a769-550353685e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some commonly used supervised and unsupervised learning algorithms:\\n\\nSupervised Learning Algorithms:\\n\\nLinear Regression\\nLogistic Regression\\nDecision Trees\\nRandom Forest\\nNaive Bayes\\nK-Nearest Neighbors (K-NN)\\nSupport Vector Machines (SVM)\\nNeural Networks (Multi-layer Perceptron)\\nGradient Boosting Machines\\nConvolutional Neural Networks (CNN)\\nRecurrent Neural Networks (RNN)\\nLong Short-Term Memory (LSTM)\\nUnsupervised Learning Algorithms:\\n\\nClustering: k-means, DBSCAN, Hierarchical Clustering\\nPrincipal Component Analysis (PCA)\\nIndependent Component Analysis (ICA)\\nAutoencoders\\nGenerative Adversarial Networks (GANs)\\nSelf-Organizing Maps (SOM)\\nIsolation Forest\\nLocal Outlier Factor (LOF)\\nt-Distributed Stochastic Neighbor Embedding (t-SNE)\\nAssociation Rule Mining (Apriori)\\nThere are many other algorithms available for both supervised and unsupervised learning, but these are some of the most commonly used ones. The choice of algorithm depends on the problem you are trying to solve, the size and complexity of the dataset, and the available computational resources.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.\n",
    "'''Here are some commonly used supervised and unsupervised learning algorithms:\n",
    "\n",
    "Supervised Learning Algorithms:\n",
    "\n",
    "Linear Regression\n",
    "Logistic Regression\n",
    "Decision Trees\n",
    "Random Forest\n",
    "Naive Bayes\n",
    "K-Nearest Neighbors (K-NN)\n",
    "Support Vector Machines (SVM)\n",
    "Neural Networks (Multi-layer Perceptron)\n",
    "Gradient Boosting Machines\n",
    "Convolutional Neural Networks (CNN)\n",
    "Recurrent Neural Networks (RNN)\n",
    "Long Short-Term Memory (LSTM)\n",
    "Unsupervised Learning Algorithms:\n",
    "\n",
    "Clustering: k-means, DBSCAN, Hierarchical Clustering\n",
    "Principal Component Analysis (PCA)\n",
    "Independent Component Analysis (ICA)\n",
    "Autoencoders\n",
    "Generative Adversarial Networks (GANs)\n",
    "Self-Organizing Maps (SOM)\n",
    "Isolation Forest\n",
    "Local Outlier Factor (LOF)\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "Association Rule Mining (Apriori)\n",
    "There are many other algorithms available for both supervised and unsupervised learning, but these are some of the most commonly used ones. The choice of algorithm depends on the problem you are trying to solve, the size and complexity of the dataset, and the available computational resources.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbb2b5-594a-4200-9e6c-d067e8deaf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
