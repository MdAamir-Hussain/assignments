{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2c4377-4f1c-4db2-a25a-0cf95cc4a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "second_row = df.iloc[1]\n",
    "print(second_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b63bd38-8ca5-421e-ae42-05e5ced35375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In pandas, the loc and iloc functions are used to access data in a DataFrame, but they have some differences in terms of indexing methods.\\n\\nloc: This function is primarily label-based, meaning it is used to access data based on the labels of rows or columns. It accepts label-based indexing and returns data based on the row and column labels.\\n\\niloc: This function is primarily integer-based, meaning it is used to access data based on the integer positions of rows or columns. It accepts integer-based indexing and returns data based on the row and column positions.\\n\\nHere are the key differences between loc and iloc:\\n\\nloc uses label-based indexing, while iloc uses integer-based indexing.\\nloc includes the end value in slicing, while iloc excludes the end value. For example, df.loc[1:3] will include rows with labels 1, 2, and 3, while df.iloc[1:3] will include rows with positions 1 and 2 (excluding 3).\\nloc can accept labels for both rows and columns, while iloc only accepts integer positions for rows and columns.\\nloc can accept boolean masks or callable functions as indexing criteria, while iloc only accepts integer positions or slices.\\nIn summary, loc is used for label-based indexing with inclusion of the end value, while iloc is used for integer-based indexing with exclusion of the end value.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.\n",
    "\n",
    "'''In pandas, the loc and iloc functions are used to access data in a DataFrame, but they have some differences in terms of indexing methods.\n",
    "\n",
    "loc: This function is primarily label-based, meaning it is used to access data based on the labels of rows or columns. It accepts label-based indexing and returns data based on the row and column labels.\n",
    "\n",
    "iloc: This function is primarily integer-based, meaning it is used to access data based on the integer positions of rows or columns. It accepts integer-based indexing and returns data based on the row and column positions.\n",
    "\n",
    "Here are the key differences between loc and iloc:\n",
    "\n",
    "loc uses label-based indexing, while iloc uses integer-based indexing.\n",
    "loc includes the end value in slicing, while iloc excludes the end value. For example, df.loc[1:3] will include rows with labels 1, 2, and 3, while df.iloc[1:3] will include rows with positions 1 and 2 (excluding 3).\n",
    "loc can accept labels for both rows and columns, while iloc only accepts integer positions for rows and columns.\n",
    "loc can accept boolean masks or callable functions as indexing criteria, while iloc only accepts integer positions or slices.\n",
    "In summary, loc is used for label-based indexing with inclusion of the end value, while iloc is used for integer-based indexing with exclusion of the end value.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08119a97-c5d4-4d28-9732-b32a786df57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "print(new_df.loc[2])\n",
    "print(new_df.iloc[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7482980f-6fbc-4537-9770-78608bd65e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.424140\n",
      "column_2    0.340754\n",
      "column_3    0.528693\n",
      "column_4    0.550529\n",
      "column_5    0.519964\n",
      "column_6    0.491545\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#4.(i)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17945b4-b646-4b86-8ade-bd02fa636735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard deviation of 'column_2':\n",
      "0.26930304080683365\n"
     ]
    }
   ],
   "source": [
    "#(ii)# Standard deviation of column 'column_2'\n",
    "column_2_std = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\")\n",
    "print(column_2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7e443a-86fc-49bd-983d-26c8ac6b81bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of column_2: 0.6022305191210536\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace data in the second row of 'column_2' with a string variable\n",
    "df1.loc[2, 'column_2'] = 'replacement_string'\n",
    "\n",
    "# Convert 'column_2' to numeric type\n",
    "df1['column_2'] = pd.to_numeric(df1['column_2'], errors='coerce')\n",
    "\n",
    "# Find the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "\n",
    "print(\"Mean of column_2:\", mean_column_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb571b2-9c08-4c98-88b6-128de590abe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In pandas, the windows functions are used for performing calculations on a rolling or expanding window of data within a DataFrame or Series. These functions allow you to apply various operations, such as aggregation, transformation, or filtering, to a specific window of data defined by its size and position.\\n\\nThe types of windows functions available in pandas are:\\n\\nRolling Windows: These functions operate on a fixed-size sliding window of data and perform calculations within that window as it moves along the data. Some common rolling windows functions include:\\n\\nrolling(): Creates a rolling window object.\\nmean(): Calculates the mean of the window.\\nsum(): Calculates the sum of the window.\\nstd(): Calculates the standard deviation of the window.\\nmin(): Calculates the minimum value in the window.\\nmax(): Calculates the maximum value in the window.\\nquantile(): Calculates the specified quantile in the window.\\napply(): Applies a custom function to the window.\\nExpanding Windows: These functions progressively expand the window size as it moves along the data. They consider all the data points from the start until the current position of the window. Some common expanding windows functions include:\\n\\nexpanding(): Creates an expanding window object.\\nmean(): Calculates the mean of the expanding window.\\nsum(): Calculates the sum of the expanding window.\\nstd(): Calculates the standard deviation of the expanding window.\\nmin(): Calculates the minimum value in the expanding window.\\nmax(): Calculates the maximum value in the expanding window.\\nquantile(): Calculates the specified quantile in the expanding window.\\napply(): Applies a custom function to the expanding window.\\nThese windows functions provide flexibility in performing calculations on rolling or expanding windows of data, allowing you to gain insights into trends, patterns, or summarize data over time.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.\n",
    "\n",
    "'''In pandas, the windows functions are used for performing calculations on a rolling or expanding window of data within a DataFrame or Series. These functions allow you to apply various operations, such as aggregation, transformation, or filtering, to a specific window of data defined by its size and position.\n",
    "\n",
    "The types of windows functions available in pandas are:\n",
    "\n",
    "Rolling Windows: These functions operate on a fixed-size sliding window of data and perform calculations within that window as it moves along the data. Some common rolling windows functions include:\n",
    "\n",
    "rolling(): Creates a rolling window object.\n",
    "mean(): Calculates the mean of the window.\n",
    "sum(): Calculates the sum of the window.\n",
    "std(): Calculates the standard deviation of the window.\n",
    "min(): Calculates the minimum value in the window.\n",
    "max(): Calculates the maximum value in the window.\n",
    "quantile(): Calculates the specified quantile in the window.\n",
    "apply(): Applies a custom function to the window.\n",
    "Expanding Windows: These functions progressively expand the window size as it moves along the data. They consider all the data points from the start until the current position of the window. Some common expanding windows functions include:\n",
    "\n",
    "expanding(): Creates an expanding window object.\n",
    "mean(): Calculates the mean of the expanding window.\n",
    "sum(): Calculates the sum of the expanding window.\n",
    "std(): Calculates the standard deviation of the expanding window.\n",
    "min(): Calculates the minimum value in the expanding window.\n",
    "max(): Calculates the maximum value in the expanding window.\n",
    "quantile(): Calculates the specified quantile in the expanding window.\n",
    "apply(): Applies a custom function to the expanding window.\n",
    "These windows functions provide flexibility in performing calculations on rolling or expanding windows of data, allowing you to gain insights into trends, patterns, or summarize data over time.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65da6774-089d-4768-a347-60d2d887d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month: 5\n",
      "Current year: 2023\n"
     ]
    }
   ],
   "source": [
    "#7.\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now()\n",
    "\n",
    "# Extract the month and year from the current date\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current month:\", current_month)\n",
    "print(\"Current year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccaa8f4-d076-446c-b43b-742dbe31f782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2002-11-11\n",
      "Enter the second date (YYYY-MM-DD):  2003-11-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between the dates:\n",
      "Days: 365\n",
      "Hours: 0\n",
      "Minutes: 0\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the dates\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert the input dates to Pandas datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# Calculate the time difference using Pandas Timedelta\n",
    "time_diff = date2 - date1\n",
    "\n",
    "# Extract the days, hours, and minutes from the time difference\n",
    "days = time_diff.days\n",
    "hours = time_diff.seconds // 3600\n",
    "minutes = (time_diff.seconds % 3600) // 60\n",
    "\n",
    "# Display the result\n",
    "print(\"Difference between the dates:\")\n",
    "print(f\"Days: {days}\")\n",
    "print(f\"Hours: {hours}\")\n",
    "print(f\"Minutes: {minutes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "933c90b1-338c-4469-b467-97305417915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file:  winequality-red.csv\n",
      "Enter the column name to convert:  chlorides\n",
      "Enter the category order (comma-separated):  Low,Medium,High\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Data:\n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar chlorides  \\\n",
      "0               7.4             0.700         0.00             1.9       NaN   \n",
      "1               7.8             0.880         0.00             2.6       NaN   \n",
      "2               7.8             0.760         0.04             2.3       NaN   \n",
      "3              11.2             0.280         0.56             1.9       NaN   \n",
      "4               7.4             0.700         0.00             1.9       NaN   \n",
      "...             ...               ...          ...             ...       ...   \n",
      "1594            6.2             0.600         0.08             2.0       NaN   \n",
      "1595            5.9             0.550         0.10             2.2       NaN   \n",
      "1596            6.3             0.510         0.13             2.3       NaN   \n",
      "1597            5.9             0.645         0.12             2.0       NaN   \n",
      "1598            6.0             0.310         0.47             3.6       NaN   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
      "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
      "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
      "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        5  \n",
      "1         9.8        5  \n",
      "2         9.8        5  \n",
      "3         9.8        6  \n",
      "4         9.4        5  \n",
      "...       ...      ...  \n",
      "1594     10.5        5  \n",
      "1595     11.2        6  \n",
      "1596     11.0        6  \n",
      "1597     10.2        5  \n",
      "1598     11.0        6  \n",
      "\n",
      "[1599 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Prompt the user to enter the column name and category order\n",
    "column_name = input(\"Enter the column name to convert: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "# Convert the specified column to a categorical data type with the specified order\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the data based on the specified column\n",
    "sorted_df = df.sort_values(by=column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280e429a-b9bc-4581-b4e4-b6e36c6cdf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Prompt the user to enter the file path\\nfile_path = input(\"Enter the file path of the CSV file: \")\\n\\n# Read the CSV file\\ndf = pd.read_csv(file_path)\\n\\n# Convert the \\'Date\\' column to a datetime type\\ndf[\\'Date\\'] = pd.to_datetime(df[\\'Date\\'])\\n\\n# Group the data by \\'Date\\' and \\'Category\\' and calculate the sum of \\'Sales\\'\\ngrouped_data = df.groupby([\\'Date\\', \\'Category\\'])[\\'Sales\\'].sum().unstack()\\n\\n# Plot the stacked bar chart\\ngrouped_data.plot(kind=\\'bar\\', stacked=True)\\n\\n# Set the chart title and axis labels\\nplt.title(\\'Sales by Product Category over Time\\')\\nplt.xlabel(\\'Date\\')\\nplt.ylabel(\\'Sales\\')\\n\\n# Show the chart\\nplt.show()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.\n",
    "\n",
    "'''import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'Date' column to a datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by 'Date' and 'Category' and calculate the sum of 'Sales'\n",
    "grouped_data = df.groupby(['Date', 'Category'])['Sales'].sum().unstack()\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "grouped_data.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set the chart title and axis labels\n",
    "plt.title('Sales by Product Category over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d0814-ac46-496b-a245-4040067680f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode()\n",
    "\n",
    "# Display the results in a table\n",
    "table_data = {'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "              'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]}\n",
    "table = pd.DataFrame(table_data)\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a53ab9-f0b3-4c34-b3e2-06a8da2e1eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
