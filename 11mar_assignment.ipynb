{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65648f6-d5ff-41f0-bdc7-5430f2c70276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Both t-test and z-test are statistical hypothesis tests used to test the significance of a sample mean. However, they differ in their assumptions about the population and sample size.\\n\\nA z-test is used when the population variance is known, and the sample size is large (typically n > 30). In contrast, a t-test is used when the population variance is unknown, and the sample size is small (typically n < 30).\\n\\nHere is an example scenario for each type of test:\\n\\nScenario for z-test:\\nSuppose we want to test if the average height of all students in a particular college is equal to 68 inches. We have a random sample of 100 students, and we know that the population standard deviation is 4 inches. In this scenario, we would use a z-test because the population standard deviation is known and the sample size is large.\\n\\nScenario for t-test:\\nSuppose we want to test if a new medication reduces the average blood pressure of patients. We have a random sample of 20 patients, and we do not know the population standard deviation. In this scenario, we would use a t-test because the population standard deviation is unknown, and the sample size is small.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.\n",
    "'''Both t-test and z-test are statistical hypothesis tests used to test the significance of a sample mean. However, they differ in their assumptions about the population and sample size.\n",
    "\n",
    "A z-test is used when the population variance is known, and the sample size is large (typically n > 30). In contrast, a t-test is used when the population variance is unknown, and the sample size is small (typically n < 30).\n",
    "\n",
    "Here is an example scenario for each type of test:\n",
    "\n",
    "Scenario for z-test:\n",
    "Suppose we want to test if the average height of all students in a particular college is equal to 68 inches. We have a random sample of 100 students, and we know that the population standard deviation is 4 inches. In this scenario, we would use a z-test because the population standard deviation is known and the sample size is large.\n",
    "\n",
    "Scenario for t-test:\n",
    "Suppose we want to test if a new medication reduces the average blood pressure of patients. We have a random sample of 20 patients, and we do not know the population standard deviation. In this scenario, we would use a t-test because the population standard deviation is unknown, and the sample size is small.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a414071a-23d5-4de8-8107-1968171324ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One-tailed and two-tailed tests are different types of statistical hypothesis tests that differ in the direction of the alternative hypothesis.\\n\\nA one-tailed test, also known as a directional test, is a hypothesis test in which the alternative hypothesis specifies the direction of the effect being tested. In other words, it is used to test whether the population parameter is greater than or less than a certain value. For example, we might use a one-tailed test to determine if the mean score of a group is greater than a certain value or less than a certain value.\\n\\nA two-tailed test, also known as a non-directional test, is a hypothesis test in which the alternative hypothesis does not specify the direction of the effect being tested. In other words, it is used to test whether the population parameter is different from a certain value. For example, we might use a two-tailed test to determine if the mean score of a group is different from a certain value.\\n\\nTo determine which type of test to use, we need to consider the research question and the alternative hypothesis. If the alternative hypothesis specifies a direction, we use a one-tailed test. If the alternative hypothesis does not specify a direction, we use a two-tailed test.\\n\\nFor example, suppose we want to test whether a new drug increases the reaction time of participants in a study. If we have a strong theoretical basis to expect that the drug will increase reaction time, we might use a one-tailed test to determine if the reaction time is significantly higher than the control group. Alternatively, if we have no strong theoretical basis to expect an increase or decrease in reaction time, we might use a two-tailed test to determine if the reaction time is significantly different from the control group.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.\n",
    "'''One-tailed and two-tailed tests are different types of statistical hypothesis tests that differ in the direction of the alternative hypothesis.\n",
    "\n",
    "A one-tailed test, also known as a directional test, is a hypothesis test in which the alternative hypothesis specifies the direction of the effect being tested. In other words, it is used to test whether the population parameter is greater than or less than a certain value. For example, we might use a one-tailed test to determine if the mean score of a group is greater than a certain value or less than a certain value.\n",
    "\n",
    "A two-tailed test, also known as a non-directional test, is a hypothesis test in which the alternative hypothesis does not specify the direction of the effect being tested. In other words, it is used to test whether the population parameter is different from a certain value. For example, we might use a two-tailed test to determine if the mean score of a group is different from a certain value.\n",
    "\n",
    "To determine which type of test to use, we need to consider the research question and the alternative hypothesis. If the alternative hypothesis specifies a direction, we use a one-tailed test. If the alternative hypothesis does not specify a direction, we use a two-tailed test.\n",
    "\n",
    "For example, suppose we want to test whether a new drug increases the reaction time of participants in a study. If we have a strong theoretical basis to expect that the drug will increase reaction time, we might use a one-tailed test to determine if the reaction time is significantly higher than the control group. Alternatively, if we have no strong theoretical basis to expect an increase or decrease in reaction time, we might use a two-tailed test to determine if the reaction time is significantly different from the control group.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b26c4079-98b7-4989-8174-1483f6dc35de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type 1 and Type 2 errors are two types of errors that can occur in hypothesis testing.\\n\\nType 1 error occurs when we reject a true null hypothesis. In other words, we conclude that there is a significant difference between the groups when there is no actual difference. This error is also known as a false positive. The probability of making a Type 1 error is denoted by alpha (α) and is typically set at 0.05.\\n\\nExample of Type 1 error:\\nSuppose a pharmaceutical company is testing a new drug to lower cholesterol levels in patients. They conduct a clinical trial and find a statistically significant difference between the group of patients who received the drug and those who received a placebo. However, it turns out that there is no actual difference in cholesterol levels between the two groups, and the difference observed in the study was due to chance. This is an example of a Type 1 error.\\n\\nType 2 error occurs when we fail to reject a false null hypothesis. In other words, we conclude that there is no significant difference between the groups when there is an actual difference. This error is also known as a false negative. The probability of making a Type 2 error is denoted by beta (β) and is typically set at 0.20.\\n\\nExample of Type 2 error:\\nSuppose a company is testing a new software to improve employee productivity. They conduct an experiment and find no significant difference between the group of employees who used the new software and those who did not. However, in reality, the software does increase productivity, and the study failed to detect this difference. This is an example of a Type 2 error.\\n\\nIn hypothesis testing, we need to balance the risk of making Type 1 and Type 2 errors. A tradeoff exists between the two errors, and reducing the risk of one error increases the risk of the other. Thus, we need to choose an appropriate level of significance (alpha) and power (1-beta) to minimize the risk of both types of errors.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.\n",
    "'''Type 1 and Type 2 errors are two types of errors that can occur in hypothesis testing.\n",
    "\n",
    "Type 1 error occurs when we reject a true null hypothesis. In other words, we conclude that there is a significant difference between the groups when there is no actual difference. This error is also known as a false positive. The probability of making a Type 1 error is denoted by alpha (α) and is typically set at 0.05.\n",
    "\n",
    "Example of Type 1 error:\n",
    "Suppose a pharmaceutical company is testing a new drug to lower cholesterol levels in patients. They conduct a clinical trial and find a statistically significant difference between the group of patients who received the drug and those who received a placebo. However, it turns out that there is no actual difference in cholesterol levels between the two groups, and the difference observed in the study was due to chance. This is an example of a Type 1 error.\n",
    "\n",
    "Type 2 error occurs when we fail to reject a false null hypothesis. In other words, we conclude that there is no significant difference between the groups when there is an actual difference. This error is also known as a false negative. The probability of making a Type 2 error is denoted by beta (β) and is typically set at 0.20.\n",
    "\n",
    "Example of Type 2 error:\n",
    "Suppose a company is testing a new software to improve employee productivity. They conduct an experiment and find no significant difference between the group of employees who used the new software and those who did not. However, in reality, the software does increase productivity, and the study failed to detect this difference. This is an example of a Type 2 error.\n",
    "\n",
    "In hypothesis testing, we need to balance the risk of making Type 1 and Type 2 errors. A tradeoff exists between the two errors, and reducing the risk of one error increases the risk of the other. Thus, we need to choose an appropriate level of significance (alpha) and power (1-beta) to minimize the risk of both types of errors.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c679cc2-f427-4fcc-a760-6220870e5d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bayes's theorem is a mathematical formula that helps us calculate the probability of a hypothesis being true given certain evidence. The formula states that the posterior probability of a hypothesis (H) given the observed evidence (E) is equal to the product of the prior probability of the hypothesis (P(H)), and the likelihood of the evidence given the hypothesis (P(E|H)), divided by the probability of the evidence (P(E)).\\n\\nIn other words, Bayes's theorem helps us update our prior beliefs about a hypothesis based on new evidence.\\n\\nHere is an example to illustrate Bayes's theorem:\\n\\nSuppose a medical test has a 99% accuracy rate in detecting a rare disease. However, the disease only occurs in 1 out of 10,000 people. You take the test, and it comes back positive. What is the probability that you actually have the disease?\\n\\nLet's apply Bayes's theorem to this scenario:\\n\\nHypothesis: You have the disease (H)\\n\\nEvidence: The test result is positive (E)\\n\\nPrior Probability: P(H) = 1/10,000 (the probability of having the disease before taking the test)\\n\\nLikelihood: P(E|H) = 0.99 (the probability of a positive test result given that you have the disease)\\n\\nComplement Probability: P(not E|not H) = 0.99 (the probability of a negative test result given that you do not have the disease)\\n\\nComplement Prior Probability: P(not H) = 1 - P(H) = 9,999/10,000 (the probability of not having the disease)\\n\\nNow, we can use Bayes's theorem to calculate the posterior probability of having the disease given a positive test result:\\n\\nP(H|E) = P(E|H) * P(H) / P(E)\\n= P(E|H) * P(H) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\\n= 0.99 * 1/10,000 / [0.99 * 1/10,000 + 0.01 * 9,999/10,000]\\n≈ 0.0098 or 0.98%\\n\\nTherefore, even though the test result is positive, the probability of actually having the disease is less than 1%. This is because the base rate of the disease is very low, and the false positive rate of the test is also non-negligible.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.\n",
    "'''Bayes's theorem is a mathematical formula that helps us calculate the probability of a hypothesis being true given certain evidence. The formula states that the posterior probability of a hypothesis (H) given the observed evidence (E) is equal to the product of the prior probability of the hypothesis (P(H)), and the likelihood of the evidence given the hypothesis (P(E|H)), divided by the probability of the evidence (P(E)).\n",
    "\n",
    "In other words, Bayes's theorem helps us update our prior beliefs about a hypothesis based on new evidence.\n",
    "\n",
    "Here is an example to illustrate Bayes's theorem:\n",
    "\n",
    "Suppose a medical test has a 99% accuracy rate in detecting a rare disease. However, the disease only occurs in 1 out of 10,000 people. You take the test, and it comes back positive. What is the probability that you actually have the disease?\n",
    "\n",
    "Let's apply Bayes's theorem to this scenario:\n",
    "\n",
    "Hypothesis: You have the disease (H)\n",
    "\n",
    "Evidence: The test result is positive (E)\n",
    "\n",
    "Prior Probability: P(H) = 1/10,000 (the probability of having the disease before taking the test)\n",
    "\n",
    "Likelihood: P(E|H) = 0.99 (the probability of a positive test result given that you have the disease)\n",
    "\n",
    "Complement Probability: P(not E|not H) = 0.99 (the probability of a negative test result given that you do not have the disease)\n",
    "\n",
    "Complement Prior Probability: P(not H) = 1 - P(H) = 9,999/10,000 (the probability of not having the disease)\n",
    "\n",
    "Now, we can use Bayes's theorem to calculate the posterior probability of having the disease given a positive test result:\n",
    "\n",
    "P(H|E) = P(E|H) * P(H) / P(E)\n",
    "= P(E|H) * P(H) / [P(E|H) * P(H) + P(E|not H) * P(not H)]\n",
    "= 0.99 * 1/10,000 / [0.99 * 1/10,000 + 0.01 * 9,999/10,000]\n",
    "≈ 0.0098 or 0.98%\n",
    "\n",
    "Therefore, even though the test result is positive, the probability of actually having the disease is less than 1%. This is because the base rate of the disease is very low, and the false positive rate of the test is also non-negligible.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cec4147-5f2f-4e8b-89c7-750416ec8588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A confidence interval is a range of values that is likely to contain the true population parameter with a certain level of confidence. In other words, it is an estimate of the precision of our sample statistic and gives us a sense of how much uncertainty there is around our estimate.\\n\\nThe calculation of a confidence interval involves three components: the sample mean (x̄), the standard deviation of the sample (s), and the sample size (n). The formula for a confidence interval is:\\n\\nConfidence Interval = x̄ ± z* (s/√n)\\n\\nWhere z* is the z-score corresponding to the desired level of confidence. For example, a 95% confidence interval corresponds to a z-score of 1.96, and a 99% confidence interval corresponds to a z-score of 2.58.\\n\\nHere is an example to illustrate how to calculate a confidence interval:\\n\\nSuppose we are interested in estimating the average height of students in a college. We randomly sample 50 students and measure their heights. The sample mean height is 170 cm, and the standard deviation is 5 cm. We want to calculate a 95% confidence interval for the population mean height.\\n\\nUsing the formula above, we have:\\n\\nConfidence Interval = 170 ± 1.96 * (5/√50)\\n\\nConfidence Interval = 170 ± 1.96 * 0.707\\n\\nConfidence Interval = (168.63, 171.37)\\n\\nTherefore, we can say with 95% confidence that the true population mean height of college students is between 168.63 cm and 171.37 cm. This means that if we were to take many random samples of the same size from the population, about 95% of the confidence intervals calculated would contain the true population mean.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.\n",
    "'''A confidence interval is a range of values that is likely to contain the true population parameter with a certain level of confidence. In other words, it is an estimate of the precision of our sample statistic and gives us a sense of how much uncertainty there is around our estimate.\n",
    "\n",
    "The calculation of a confidence interval involves three components: the sample mean (x̄), the standard deviation of the sample (s), and the sample size (n). The formula for a confidence interval is:\n",
    "\n",
    "Confidence Interval = x̄ ± z* (s/√n)\n",
    "\n",
    "Where z* is the z-score corresponding to the desired level of confidence. For example, a 95% confidence interval corresponds to a z-score of 1.96, and a 99% confidence interval corresponds to a z-score of 2.58.\n",
    "\n",
    "Here is an example to illustrate how to calculate a confidence interval:\n",
    "\n",
    "Suppose we are interested in estimating the average height of students in a college. We randomly sample 50 students and measure their heights. The sample mean height is 170 cm, and the standard deviation is 5 cm. We want to calculate a 95% confidence interval for the population mean height.\n",
    "\n",
    "Using the formula above, we have:\n",
    "\n",
    "Confidence Interval = 170 ± 1.96 * (5/√50)\n",
    "\n",
    "Confidence Interval = 170 ± 1.96 * 0.707\n",
    "\n",
    "Confidence Interval = (168.63, 171.37)\n",
    "\n",
    "Therefore, we can say with 95% confidence that the true population mean height of college students is between 168.63 cm and 171.37 cm. This means that if we were to take many random samples of the same size from the population, about 95% of the confidence intervals calculated would contain the true population mean.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9234d6c-2d03-4d6e-8b72-4e812d8294e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Problem:\\nSuppose a factory produces two types of toys: Type A and Type B. It is known that 30% of the toys produced are Type A and 70% are Type B. Further, it is known that 10% of the Type A toys and 90% of the Type B toys are defective. If a toy is chosen at random from the factory and is found to be defective, what is the probability that it is a Type A toy?\\n\\nSolution:\\nLet A represent the event that the toy is Type A, and D represent the event that the toy is defective. We are given P(A) = 0.3, P(B) = 0.7, P(D|A) = 0.1, and P(D|B) = 0.9. We want to calculate P(A|D), the probability that the toy is Type A given that it is defective.\\n\\nWe can use Bayes' Theorem to calculate P(A|D):\\n\\nP(A|D) = P(D|A) * P(A) / P(D)\\n\\nwhere P(D) is the probability of the toy being defective, which can be calculated using the law of total probability:\\n\\nP(D) = P(D|A) * P(A) + P(D|B) * P(B)\\n= 0.1 * 0.3 + 0.9 * 0.7\\n= 0.64\\n\\nNow, we can substitute in the values and calculate:\\n\\nP(A|D) = P(D|A) * P(A) / P(D)\\n= 0.1 * 0.3 / 0.64\\n= 0.0469 or 4.69%\\n\\nTherefore, the probability that the toy is Type A given that it is defective is only 4.69%. This means that even though Type A toys are less likely to be defective than Type B toys, the higher proportion of Type B toys in the factory means that the overall probability of a defective toy being Type B is much higher.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.\n",
    "'''Problem:\n",
    "Suppose a factory produces two types of toys: Type A and Type B. It is known that 30% of the toys produced are Type A and 70% are Type B. Further, it is known that 10% of the Type A toys and 90% of the Type B toys are defective. If a toy is chosen at random from the factory and is found to be defective, what is the probability that it is a Type A toy?\n",
    "\n",
    "Solution:\n",
    "Let A represent the event that the toy is Type A, and D represent the event that the toy is defective. We are given P(A) = 0.3, P(B) = 0.7, P(D|A) = 0.1, and P(D|B) = 0.9. We want to calculate P(A|D), the probability that the toy is Type A given that it is defective.\n",
    "\n",
    "We can use Bayes' Theorem to calculate P(A|D):\n",
    "\n",
    "P(A|D) = P(D|A) * P(A) / P(D)\n",
    "\n",
    "where P(D) is the probability of the toy being defective, which can be calculated using the law of total probability:\n",
    "\n",
    "P(D) = P(D|A) * P(A) + P(D|B) * P(B)\n",
    "= 0.1 * 0.3 + 0.9 * 0.7\n",
    "= 0.64\n",
    "\n",
    "Now, we can substitute in the values and calculate:\n",
    "\n",
    "P(A|D) = P(D|A) * P(A) / P(D)\n",
    "= 0.1 * 0.3 / 0.64\n",
    "= 0.0469 or 4.69%\n",
    "\n",
    "Therefore, the probability that the toy is Type A given that it is defective is only 4.69%. This means that even though Type A toys are less likely to be defective than Type B toys, the higher proportion of Type B toys in the factory means that the overall probability of a defective toy being Type B is much higher.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cebb6be1-b213-408c-917b-f8efad558f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the 95% confidence interval, we need to use the following formula:\\n\\nConfidence Interval = sample mean ± (z-score * standard error)\\n\\nwhere the standard error is calculated as standard deviation / square root of sample size, and the z-score for a 95% confidence interval is 1.96.\\n\\nPlugging in the given values, we get:\\n\\nConfidence Interval = 50 ± (1.96 * (5 / sqrt(n)))\\n\\nSince the sample size (n) is not given, we cannot calculate the standard error or the confidence interval. However, if we assume a sample size of 100, for example, we get:\\n\\nConfidence Interval = 50 ± (1.96 * (5 / sqrt(100)))\\n\\nConfidence Interval = 50 ± (0.98)\\n\\nConfidence Interval = (49.02, 50.98)\\n\\nInterpretation:\\n\\nWe can interpret the 95% confidence interval as a range of values that we can be 95% confident contains the true population mean. In this case, the confidence interval is (49.02, 50.98), which means that we can be 95% confident that the true population mean falls between 49.02 and 50.98. We can also say that if we were to repeat this experiment many times and calculate the confidence interval for each sample, 95% of those intervals would contain the true population mean.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.\n",
    "'''To calculate the 95% confidence interval, we need to use the following formula:\n",
    "\n",
    "Confidence Interval = sample mean ± (z-score * standard error)\n",
    "\n",
    "where the standard error is calculated as standard deviation / square root of sample size, and the z-score for a 95% confidence interval is 1.96.\n",
    "\n",
    "Plugging in the given values, we get:\n",
    "\n",
    "Confidence Interval = 50 ± (1.96 * (5 / sqrt(n)))\n",
    "\n",
    "Since the sample size (n) is not given, we cannot calculate the standard error or the confidence interval. However, if we assume a sample size of 100, for example, we get:\n",
    "\n",
    "Confidence Interval = 50 ± (1.96 * (5 / sqrt(100)))\n",
    "\n",
    "Confidence Interval = 50 ± (0.98)\n",
    "\n",
    "Confidence Interval = (49.02, 50.98)\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "We can interpret the 95% confidence interval as a range of values that we can be 95% confident contains the true population mean. In this case, the confidence interval is (49.02, 50.98), which means that we can be 95% confident that the true population mean falls between 49.02 and 50.98. We can also say that if we were to repeat this experiment many times and calculate the confidence interval for each sample, 95% of those intervals would contain the true population mean.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92555c82-8cb9-4604-b448-dfea9747dea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The margin of error in a confidence interval is the amount of error that we allow for when we estimate a population parameter based on a sample statistic. It is usually represented as a range of values that extends from the sample statistic in both directions.\\n\\nThe margin of error is affected by a variety of factors, including the sample size, the level of confidence, and the variability of the data. In general, larger sample sizes tend to result in smaller margins of error, while smaller sample sizes tend to result in larger margins of error.\\n\\nThis is because larger sample sizes provide more information about the population, which leads to more precise estimates of the population parameters. As the sample size increases, the standard error decreases, which means that the margin of error decreases as well.\\n\\nFor example, suppose we want to estimate the proportion of voters in a certain state who support a particular candidate. We take a random sample of 1000 voters and find that 60% of them support the candidate. We calculate a 95% confidence interval and get a margin of error of 3.1%. This means that we can be 95% confident that the true proportion of voters who support the candidate is between 56.9% and 63.1%.\\n\\nIf we increase the sample size to 2000, the margin of error would decrease, assuming that the same level of confidence is maintained. The new margin of error would be:\\n\\nMargin of error = 1.96 * sqrt[(0.6 * 0.4) / 2000] = 2.2%\\n\\nThis means that we can be 95% confident that the true proportion of voters who support the candidate is between 57.8% and 62.2%. As we can see, the larger sample size resulted in a smaller margin of error, which means that we have more precise estimates of the population parameter.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.\n",
    "'''The margin of error in a confidence interval is the amount of error that we allow for when we estimate a population parameter based on a sample statistic. It is usually represented as a range of values that extends from the sample statistic in both directions.\n",
    "\n",
    "The margin of error is affected by a variety of factors, including the sample size, the level of confidence, and the variability of the data. In general, larger sample sizes tend to result in smaller margins of error, while smaller sample sizes tend to result in larger margins of error.\n",
    "\n",
    "This is because larger sample sizes provide more information about the population, which leads to more precise estimates of the population parameters. As the sample size increases, the standard error decreases, which means that the margin of error decreases as well.\n",
    "\n",
    "For example, suppose we want to estimate the proportion of voters in a certain state who support a particular candidate. We take a random sample of 1000 voters and find that 60% of them support the candidate. We calculate a 95% confidence interval and get a margin of error of 3.1%. This means that we can be 95% confident that the true proportion of voters who support the candidate is between 56.9% and 63.1%.\n",
    "\n",
    "If we increase the sample size to 2000, the margin of error would decrease, assuming that the same level of confidence is maintained. The new margin of error would be:\n",
    "\n",
    "Margin of error = 1.96 * sqrt[(0.6 * 0.4) / 2000] = 2.2%\n",
    "\n",
    "This means that we can be 95% confident that the true proportion of voters who support the candidate is between 57.8% and 62.2%. As we can see, the larger sample size resulted in a smaller margin of error, which means that we have more precise estimates of the population parameter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53573c79-f932-4b72-bae5-22660f783738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the z-score, we use the following formula:\\n\\nz = (x - μ) / σ\\n\\nwhere x is the data point, μ is the population mean, and σ is the population standard deviation.\\n\\nPlugging in the given values, we get:\\n\\nz = (75 - 70) / 5\\n\\nz = 1\\n\\nInterpretation:\\n\\nThe z-score of 1 means that the data point of 75 is one standard deviation above the population mean of 70. In other words, the value of 75 is higher than the average value in the population by one standard deviation. This information can be used to determine the relative position of the data point within the population and to compare it to other data points that have been standardized using the same population parameters.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9.\n",
    "'''To calculate the z-score, we use the following formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the population mean, and σ is the population standard deviation.\n",
    "\n",
    "Plugging in the given values, we get:\n",
    "\n",
    "z = (75 - 70) / 5\n",
    "\n",
    "z = 1\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The z-score of 1 means that the data point of 75 is one standard deviation above the population mean of 70. In other words, the value of 75 is higher than the average value in the population by one standard deviation. This information can be used to determine the relative position of the data point within the population and to compare it to other data points that have been standardized using the same population parameters.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3aae5b9-7f98-4b2a-a830-acde265911a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence level using a t-test, we need to set up the null and alternative hypotheses and calculate the t-statistic and the p-value.\\n\\nNull hypothesis: The weight loss drug is not significantly effective, and the average weight loss in the population is not different from the sample mean.\\n\\nAlternative hypothesis: The weight loss drug is significantly effective, and the average weight loss in the population is different from the sample mean.\\n\\nWe can set the level of significance (alpha) to 0.05, which means we want to be 95% confident in our conclusions.\\n\\nThe t-statistic can be calculated using the formula:\\n\\nt = (x̄ - μ) / (s / √n)\\n\\nwhere x̄ is the sample mean, μ is the population mean (assumed to be zero under the null hypothesis), s is the sample standard deviation, and n is the sample size.\\n\\nPlugging in the given values, we get:\\n\\nt = (6 - 0) / (2.5 / √50)\\n\\nt = 12\\n\\nThe degrees of freedom for a t-test with a sample size of 50 are 49.\\n\\nWe can use a t-table or a t-test calculator to find the p-value associated with the calculated t-statistic. The p-value is the probability of getting a t-statistic as extreme or more extreme than the calculated one, assuming the null hypothesis is true.\\n\\nUsing a t-table or a t-test calculator, we find that the p-value is less than 0.0001, which is much smaller than the significance level of 0.05. Therefore, we reject the null hypothesis and conclude that the weight loss drug is significantly effective.\\n\\nInterpretation: The sample of 50 participants lost an average of 6 pounds, which is significantly different from the population mean of zero pounds. This means that the weight loss drug is effective in helping people lose weight, at a 95% confidence level.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.\n",
    "'''To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence level using a t-test, we need to set up the null and alternative hypotheses and calculate the t-statistic and the p-value.\n",
    "\n",
    "Null hypothesis: The weight loss drug is not significantly effective, and the average weight loss in the population is not different from the sample mean.\n",
    "\n",
    "Alternative hypothesis: The weight loss drug is significantly effective, and the average weight loss in the population is different from the sample mean.\n",
    "\n",
    "We can set the level of significance (alpha) to 0.05, which means we want to be 95% confident in our conclusions.\n",
    "\n",
    "The t-statistic can be calculated using the formula:\n",
    "\n",
    "t = (x̄ - μ) / (s / √n)\n",
    "\n",
    "where x̄ is the sample mean, μ is the population mean (assumed to be zero under the null hypothesis), s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "Plugging in the given values, we get:\n",
    "\n",
    "t = (6 - 0) / (2.5 / √50)\n",
    "\n",
    "t = 12\n",
    "\n",
    "The degrees of freedom for a t-test with a sample size of 50 are 49.\n",
    "\n",
    "We can use a t-table or a t-test calculator to find the p-value associated with the calculated t-statistic. The p-value is the probability of getting a t-statistic as extreme or more extreme than the calculated one, assuming the null hypothesis is true.\n",
    "\n",
    "Using a t-table or a t-test calculator, we find that the p-value is less than 0.0001, which is much smaller than the significance level of 0.05. Therefore, we reject the null hypothesis and conclude that the weight loss drug is significantly effective.\n",
    "\n",
    "Interpretation: The sample of 50 participants lost an average of 6 pounds, which is significantly different from the population mean of zero pounds. This means that the weight loss drug is effective in helping people lose weight, at a 95% confidence level.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9c4b1c-8dff-43da-91cd-b87bec31042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\\n\\nCI = p ± z* (sqrt(p*(1-p)/n))\\n\\nwhere CI is the confidence interval, p is the sample proportion (0.65), z* is the z-score corresponding to the desired confidence level (1.96 for a 95% confidence level), and n is the sample size (500).\\n\\nPlugging in the given values, we get:\\n\\nCI = 0.65 ± 1.96 * (sqrt(0.65*(1-0.65)/500))\\n\\nCI = 0.65 ± 0.044\\n\\nThe 95% confidence interval for the true proportion of people who are satisfied with their job is (0.606, 0.694). This means that we can be 95% confident that the true proportion of people who are satisfied with their job falls within this interval.\\n\\nInterpretation: Based on the survey of 500 people, we can be 95% confident that between 60.6% and 69.4% of the population of all people are satisfied with their job.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.\n",
    "'''To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\n",
    "\n",
    "CI = p ± z* (sqrt(p*(1-p)/n))\n",
    "\n",
    "where CI is the confidence interval, p is the sample proportion (0.65), z* is the z-score corresponding to the desired confidence level (1.96 for a 95% confidence level), and n is the sample size (500).\n",
    "\n",
    "Plugging in the given values, we get:\n",
    "\n",
    "CI = 0.65 ± 1.96 * (sqrt(0.65*(1-0.65)/500))\n",
    "\n",
    "CI = 0.65 ± 0.044\n",
    "\n",
    "The 95% confidence interval for the true proportion of people who are satisfied with their job is (0.606, 0.694). This means that we can be 95% confident that the true proportion of people who are satisfied with their job falls within this interval.\n",
    "\n",
    "Interpretation: Based on the survey of 500 people, we can be 95% confident that between 60.6% and 69.4% of the population of all people are satisfied with their job.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a421ba76-063e-4733-b929-8fe1fda4e910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To test if there is a significant difference in student performance between the two teaching methods, we can use a two-sample t-test. The null hypothesis (H0) is that there is no difference between the mean scores of the two teaching methods, while the alternative hypothesis (H1) is that there is a significant difference between them.\\n\\nAssuming equal variances, the formula for the two-sample t-test is:\\n\\nt = (x̄1 - x̄2) / (s_p * sqrt(1/n1 + 1/n2))\\n\\nwhere x̄1 and x̄2 are the sample means, s_p is the pooled standard deviation, n1 and n2 are the sample sizes.\\n\\nThe pooled standard deviation is calculated as:\\n\\ns_p = sqrt(((n1 - 1)*s1^2 + (n2 - 1)*s2^2) / (n1 + n2 - 2))\\n\\nwhere s1 and s2 are the sample standard deviations.\\n\\nWith a significance level of 0.01 and degrees of freedom (df) = n1 + n2 - 2 = 18, the critical t-value (t_crit) is ±2.878. If the calculated t-value is greater than t_crit or less than negative t_crit, we reject the null hypothesis.\\n\\nPlugging in the values from the question, we get:\\n\\nx̄1 = 85\\ns1 = 6\\nn1 = 10\\n\\nx̄2 = 82\\ns2 = 5\\nn2 = 10\\n\\ns_p = sqrt(((10 - 1)*6^2 + (10 - 1)*5^2) / (10 + 10 - 2)) = 5.315\\n\\nt = (85 - 82) / (5.315 * sqrt(1/10 + 1/10)) = 1.637\\n\\nSince the calculated t-value (1.637) is less than t_crit (±2.878), we fail to reject the null hypothesis. This means that we do not have enough evidence to conclude that there is a significant difference in student performance between the two teaching methods at the 0.01 significance level.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12.\n",
    "'''To test if there is a significant difference in student performance between the two teaching methods, we can use a two-sample t-test. The null hypothesis (H0) is that there is no difference between the mean scores of the two teaching methods, while the alternative hypothesis (H1) is that there is a significant difference between them.\n",
    "\n",
    "Assuming equal variances, the formula for the two-sample t-test is:\n",
    "\n",
    "t = (x̄1 - x̄2) / (s_p * sqrt(1/n1 + 1/n2))\n",
    "\n",
    "where x̄1 and x̄2 are the sample means, s_p is the pooled standard deviation, n1 and n2 are the sample sizes.\n",
    "\n",
    "The pooled standard deviation is calculated as:\n",
    "\n",
    "s_p = sqrt(((n1 - 1)*s1^2 + (n2 - 1)*s2^2) / (n1 + n2 - 2))\n",
    "\n",
    "where s1 and s2 are the sample standard deviations.\n",
    "\n",
    "With a significance level of 0.01 and degrees of freedom (df) = n1 + n2 - 2 = 18, the critical t-value (t_crit) is ±2.878. If the calculated t-value is greater than t_crit or less than negative t_crit, we reject the null hypothesis.\n",
    "\n",
    "Plugging in the values from the question, we get:\n",
    "\n",
    "x̄1 = 85\n",
    "s1 = 6\n",
    "n1 = 10\n",
    "\n",
    "x̄2 = 82\n",
    "s2 = 5\n",
    "n2 = 10\n",
    "\n",
    "s_p = sqrt(((10 - 1)*6^2 + (10 - 1)*5^2) / (10 + 10 - 2)) = 5.315\n",
    "\n",
    "t = (85 - 82) / (5.315 * sqrt(1/10 + 1/10)) = 1.637\n",
    "\n",
    "Since the calculated t-value (1.637) is less than t_crit (±2.878), we fail to reject the null hypothesis. This means that we do not have enough evidence to conclude that there is a significant difference in student performance between the two teaching methods at the 0.01 significance level.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f45bf9-0b98-4661-b5f0-a32da8643dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the 90% confidence interval for the population mean, we can use the formula:\\n\\nCI = x̄ ± z * (σ / sqrt(n))\\n\\nwhere CI is the confidence interval, x̄ is the sample mean, z is the z-score corresponding to the desired confidence level, σ is the population standard deviation, and n is the sample size.\\n\\nAt a 90% confidence level, the z-score is 1.645.\\n\\nPlugging in the values from the question, we get:\\n\\nCI = 65 ± 1.645 * (8 / sqrt(50))\\n\\nCI = 65 ± 2.306\\n\\nThe 90% confidence interval for the true population mean is (62.694, 67.306). This means that we can be 90% confident that the true population mean falls within this interval.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13.\n",
    "'''To calculate the 90% confidence interval for the population mean, we can use the formula:\n",
    "\n",
    "CI = x̄ ± z * (σ / sqrt(n))\n",
    "\n",
    "where CI is the confidence interval, x̄ is the sample mean, z is the z-score corresponding to the desired confidence level, σ is the population standard deviation, and n is the sample size.\n",
    "\n",
    "At a 90% confidence level, the z-score is 1.645.\n",
    "\n",
    "Plugging in the values from the question, we get:\n",
    "\n",
    "CI = 65 ± 1.645 * (8 / sqrt(50))\n",
    "\n",
    "CI = 65 ± 2.306\n",
    "\n",
    "The 90% confidence interval for the true population mean is (62.694, 67.306). This means that we can be 90% confident that the true population mean falls within this interval.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7698591-a438-40bb-9692-9d49cc01afbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we need to set up the null and alternative hypotheses:\\n\\nNull hypothesis (H0): Caffeine has no significant effect on reaction time.\\n\\nAlternative hypothesis (Ha): Caffeine has a significant effect on reaction time.\\n\\nWe can use a t-test to test this hypothesis, since we have a sample size of 30 and do not know the population standard deviation. Assuming a two-tailed test, with a significance level of 0.1 (90% confidence level), the critical t-value for 29 degrees of freedom is ±1.699.\\n\\nTo calculate the t-value for the sample, we use the formula:\\n\\nt = (x̄ - μ) / (s / sqrt(n))\\n\\nwhere t is the t-value, x̄ is the sample mean, μ is the population mean (which we assume to be 0 for the null hypothesis), s is the sample standard deviation, and n is the sample size.\\n\\nPlugging in the values from the question, we get:\\n\\nt = (0.25 - 0) / (0.05 / sqrt(30))\\n\\nt = 5.477\\n\\nSince the calculated t-value (5.477) is greater than the critical t-value (±1.699), we can reject the null hypothesis and conclude that caffeine has a significant effect on reaction time.\\n\\nTherefore, we can conclude that there is evidence to suggest that caffeine has a significant effect on reaction time at a 90% confidence level.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14.\n",
    "'''To conduct a hypothesis test to determine if caffeine has a significant effect on reaction time, we need to set up the null and alternative hypotheses:\n",
    "\n",
    "Null hypothesis (H0): Caffeine has no significant effect on reaction time.\n",
    "\n",
    "Alternative hypothesis (Ha): Caffeine has a significant effect on reaction time.\n",
    "\n",
    "We can use a t-test to test this hypothesis, since we have a sample size of 30 and do not know the population standard deviation. Assuming a two-tailed test, with a significance level of 0.1 (90% confidence level), the critical t-value for 29 degrees of freedom is ±1.699.\n",
    "\n",
    "To calculate the t-value for the sample, we use the formula:\n",
    "\n",
    "t = (x̄ - μ) / (s / sqrt(n))\n",
    "\n",
    "where t is the t-value, x̄ is the sample mean, μ is the population mean (which we assume to be 0 for the null hypothesis), s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "Plugging in the values from the question, we get:\n",
    "\n",
    "t = (0.25 - 0) / (0.05 / sqrt(30))\n",
    "\n",
    "t = 5.477\n",
    "\n",
    "Since the calculated t-value (5.477) is greater than the critical t-value (±1.699), we can reject the null hypothesis and conclude that caffeine has a significant effect on reaction time.\n",
    "\n",
    "Therefore, we can conclude that there is evidence to suggest that caffeine has a significant effect on reaction time at a 90% confidence level.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc98053-ddb9-4401-9715-0d2b4e35841b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
